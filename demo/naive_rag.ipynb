{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture --no-stderr\n",
    "# %pip install -U --quiet langchain-community tiktoken langchain-openai langchainhub chromadb langchain langgraph langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Config\n",
    "\n",
    "## 1.1 config environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get root directory\n",
    "root_dir = str(Path().absolute().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load environment variables\n",
    "from dotenv import load_dotenv\n",
    "env_path = f\"{root_dir}/.env\"\n",
    "load_dotenv(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 config llm and embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"doubao-1-5-lite-32k-250115\",\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.environ.get(\"OPENAI_API_URL\"),\n",
    "    openai_proxy=\"http://127.0.0.1:7890\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings(\n",
    "    model=os.environ.get(\"EMBEDDING_MODEL\"),\n",
    "    api_key=os.environ.get(\"EMBEDDING_API_KEY\"),\n",
    "    base_url=os.environ.get(\"EMBEDDING_API_URL\"),\n",
    "    openai_proxy=\"http://127.0.0.1:7890\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 config input / output file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_file_path = f\"{root_dir}/data/input/context-1000.csv\"\n",
    "ap_file_path = f\"{root_dir}/data/output/attack_prompt.csv\"\n",
    "dataset_file_path = f\"{root_dir}/data/output/dataset.csv\"\n",
    "response_file_path = f\"{root_dir}/data/output/attack_prompt_response.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 import input context and preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = pd.read_csv(context_file_path)\n",
    "contexts = contexts[\"context\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split text into sentences\n",
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=4000, chunk_overlap=200\n",
    ")\n",
    "\n",
    "contexts_splits = []\n",
    "for context in contexts:\n",
    "    contexts_splits.extend(splitter.split_text(context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(contexts_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 config chroma vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(\n",
    "    collection_name=\"retrieval_database\",\n",
    "    persist_directory=f\"{root_dir}/data/database/chroma/\",\n",
    "    embedding_function=embedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only run this if you want to create a new database\n",
    "vectordb.from_texts(\n",
    "    collection_name=\"retrieval_database\",\n",
    "    texts=contexts_splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=f\"{root_dir}/data/database/chroma/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectordb.get()['documents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build RAG System\n",
    "\n",
    "## 2.1 construct rag system graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from typing_extensions import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state class\n",
    "class State(TypedDict):\n",
    "    query: str\n",
    "    contexts: list[str]\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodes\n",
    "def retrieve(state: State):\n",
    "    query = state[\"query\"]\n",
    "    contexts = vectordb.similarity_search(query=query, k=5)\n",
    "    contexts = [context.page_content for context in contexts]\n",
    "    return {\"query\": query, \"contexts\": contexts}\n",
    "\n",
    "def generate(state: State):\n",
    "    query = state[\"query\"]\n",
    "    contexts = state[\"contexts\"]\n",
    "    \n",
    "    contexts = \"\\n\\n\".join(context for context in contexts)\n",
    "\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    response = rag_chain.invoke({\"question\": query, \"context\": contexts})\n",
    "\n",
    "    return {\"query\": query, \"contexts\": contexts, \"response\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the graph\n",
    "state = State(\n",
    "    query=\"I am a parent concerned about my child's health. I know that my child has been pooing 5 - 6 times a day for a week, which increased to 7 times in the last few days. The poo is watery with green stringy bits and there is a very bad nappy rash. The recovery time is estimated to be 5 - 7 days. Based on this information, please query the diagnosis and any cautions from the RAG system.\",\n",
    ")\n",
    "\n",
    "graph.invoke(state)['response']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 generate response for attack prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ap_file_path)\n",
    "contexts = pd.read_csv(context_file_path)\n",
    "df[\"context\"] = contexts.iloc[:, 0]\n",
    "df = df[df[\"privacy_info\"] != \"{}\"]\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def process_query(query):\n",
    "    state = State(query=query)\n",
    "    try:\n",
    "        graph.invoke(state)\n",
    "        return state[\"response\"]\n",
    "    except:\n",
    "        for _ in range(5):\n",
    "            time.sleep(5)\n",
    "            try:\n",
    "                graph.invoke(state)\n",
    "                return state[\"response\"]\n",
    "            except:\n",
    "                raise Exception(\"Failed to generate response\")\n",
    "    return graph.invoke(state)[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a response column if it doesn't exist\n",
    "if \"response\" not in df.columns:\n",
    "    df[\"response\"] = None\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "if os.path.exists(response_file_path):\n",
    "    df = pd.read_csv(response_file_path)\n",
    "\n",
    "# Process each attack prompt and store the response\n",
    "for i in tqdm(range(len(df))):\n",
    "    if not pd.isna(df.loc[i, \"response\"]):\n",
    "        continue\n",
    "    df.loc[i, \"response\"] = process_query(df[\"attack_prompt\"][i])\n",
    "    if i % batch_size == 0 or i == len(df) - 1:\n",
    "        df.to_csv(response_file_path, index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragpas.privacy import calculateAttackExtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "dataset = pd.DataFrame(columns=[\"response\", \"guidance\", \"context\", \"target\", \"privacy_info\"]).to_csv(dataset_file_path, index=False)\n",
    "\n",
    "batch_responses = []\n",
    "batch_guidances = []\n",
    "batch_contexts = []\n",
    "batch_targets = []\n",
    "batch_privacy_info = []\n",
    "\n",
    "df = pd.read_csv(response_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in tqdm(enumerate(df.itertuples()), total=len(df)):\n",
    "\n",
    "    score, feedback = calculateAttackExtraction(\n",
    "        response=row.response,\n",
    "        privacy_info=row.privacy_info,\n",
    "        target=row.target,\n",
    "        feedback=True\n",
    "    )\n",
    "\n",
    "    batch_responses.append(row.response)\n",
    "    batch_guidances.append(feedback)\n",
    "    batch_contexts.append(row.context)\n",
    "    batch_targets.append(row.target)\n",
    "    batch_privacy_info.append(row.privacy_info)\n",
    "\n",
    "    if (i + 1) % batch_size == 0 or i == len(df) - 1:\n",
    "        batch = pd.DataFrame({\n",
    "            \"response\": batch_responses,\n",
    "            \"guidance\": batch_guidances,\n",
    "            \"context\": batch_contexts,\n",
    "            \"target\": batch_targets,\n",
    "            \"privacy_info\": batch_privacy_info\n",
    "        })\n",
    "        batch.to_csv(dataset_file_path, mode=\"a\", header=False, index=False)\n",
    "        batch_responses = []\n",
    "        batch_guidances = []\n",
    "        batch_contexts = []\n",
    "        batch_targets = []\n",
    "        batch_privacy_info = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
